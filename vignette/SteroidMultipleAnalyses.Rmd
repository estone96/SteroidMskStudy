---
title: "Running multiple analyses (Systemic Steroid Cohort) at once using the CohortMethod package"
author: "Sun Geu Chae and Yeesuk Kim"
date: "`r Sys.Date()`"
output:
  pdf_document:
    number_sections: yes
    toc: yes
  html_document:
    number_sections: yes
    toc: yes
vignette: >
  %\VignetteIndexEntry{Multiple analyses using CohortMethod}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

Run CohortMethod Package

```{r, echo = FALSE, message = FALSE, warning = FALSE}
library(CohortMethod)
```
# Introduction
Glucocorticoids are a class of corticosteroids, which are a class of steroid hormones. Glucocorticoids are corticosteroids that bind to the glucocorticoid receptor that is present in almost every vertebrate animal cell. The name "glucocorticoid" is a portmanteau (glucose + cortex + steroid) and is composed from its role in regulation of glucose metabolism, synthesis in the adrenal cortex, and its steroidal structure (see structure to the right).

Glucocorticoids are part of the feedback mechanism in the immune system, which reduces certain aspects of immune function, such as inflammation. They are therefore used in medicine to treat diseases caused by an overactive immune system, such as allergies, asthma, autoimmune diseases, and sepsis. Glucocorticoids have many diverse (pleiotropic) effects, including potentially harmful side effects, and as a result are rarely sold over the counter. They also interfere with some of the abnormal mechanisms in cancer cells, so they are used in high doses to treat cancer. This includes inhibitory effects on lymphocyte proliferation, as in the treatment of lymphomas and leukemias, and the mitigation of side effects of anticancer drugs.

Glucocorticoids affect cells by binding to the glucocorticoid receptor. The activated glucocorticoid receptor-glucocorticoid complex up-regulates the expression of anti-inflammatory proteins in the nucleus (a process known as transactivation) and represses the expression of proinflammatory proteins in the cytosol by preventing the translocation of other transcription factors from the cytosol into the nucleus (transrepression).

Glucocorticoids are distinguished from mineralocorticoids and sex steroids by their specific receptors, target cells, and effects. In technical terms, "corticosteroid" refers to both glucocorticoids and mineralocorticoids (as both are mimics of hormones produced by the adrenal cortex), but is often used as a synonym for "glucocorticoid". Glucocorticoids are chiefly produced in the zona fasciculata of the adrenal cortex, whereas mineralocorticoids are synthesized in the zona glomerulosa.

Cortisol (or hydrocortisone) is the most important human glucocorticoid. It is essential for life, and it regulates or supports a variety of important cardiovascular, metabolic, immunologic, and homeostatic functions. Various synthetic glucocorticoids are available; these are widely utilized in general medical practice and numerous specialties either as replacement therapy in glucocorticoid deficiency or to suppress the immune system.

Side effects

Immunodeficiency (see section below)
Hyperglycemia due to increased gluconeogenesis, insulin resistance, and impaired glucose tolerance ("steroid diabetes"); caution in those with diabetes mellitus
Increased skin fragility, easy bruising
Negative calcium balance due to reduced intestinal calcium absorption[42]
Steroid-induced osteoporosis: reduced bone density (osteoporosis, osteonecrosis, higher fracture risk, slower fracture repair)
Weight gain due to increased visceral and truncal fat deposition (central obesity) and appetite stimulation; see corticosteroid-induced lipodystrophy
Hypercortisolemia with prolonged or excessive use (also known as, exogenous Cushing's syndrome)
Impaired memory and attention deficits[43]
Adrenal insufficiency (if used for long time and stopped suddenly without a taper)
Muscle and tendon breakdown (proteolysis), weakness, reduced muscle mass and repair[44][25]
Expansion of malar fat pads and dilation of small blood vessels in skin
Lipomatosis within the epidural space[45]
Excitatory effect on central nervous system (euphoria, psychosis)
Anovulation, irregularity of menstrual periods
Growth failure, delayed puberty
Increased plasma amino acids, increased urea formation, negative nitrogen balance
Glaucoma due to increased ocular pressure
Cataracts
Topical steroid addiction

# General approach

The general approach to running a set of analyses is that you specify all the function arguments of the functions you would normally call, and create sets of these function arguments. The final outcome models as well as intermediate data objects will all be saved to disk for later extraction. 

An analysis will be executed by calling these functions in sequence:

1. `getDbCohortMethodData()`
2. `createStudyPopulation()`
2. `createPs()` (optional)
3. `trimByPs()` or `trimByPsToEquipoise()` (optional)
4. `matchOnPs()`, `matchOnPsAndCovariates()`, `stratifyByPs()`, or `stratifyByPsAndCovariates()` (optional)
5. `fitOutcomeModel()` (optional)

When you provide several analyses to the `CohortMethod` package, it will determine whether any of the analyses have anything in common, and will take advantage of this fact. For example, if we specify several analyses that only differ in the way the outcome model is fitted, then `CohortMethod` will extract the data and fit the propensity model only once, and re-use this in all the analyses. 

The function arguments you need to define have been divided into four groups:

1. **Hypothesis of interest**: arguments that are specific to a hypothesis of interest, in the case of the cohort method this is a combination of target, comparator, and outcome.
2. **Analyses**: arguments that are not directly specific to a hypothesis of interest, such as the washout window, whether to include drugs as covariates, etc.
3. Arguments that are the output of a previous function in the `CohortMethod` package, such as the `cohortMethodData` argument of the `createPs` function. These cannot be specified by the user.
4. Arguments that are specific to an environment, such as the connection details for connecting to the server, and the name of the schema holding the CDM data.

There are a two arguments (`excludedCovariateConceptIds`, and `includedCovariateConceptIds` of the `getDbCohortMethodData()` function) that can be argued to be part both of group 1 and 2. These arguments are therefore present in both groups, and when executing the analysis the union of the two lists of concept IDs will be used.

#How to run
==========
1. In `R`, use the following code to install the dependencies:

```{r}
install.packages("devtools")
	library(devtools)
	install_github("ohdsi/ParallelLogger", ref = "v1.1.1")
	install_github("ohdsi/SqlRender", ref = "v1.6.3")
	install_github("ohdsi/DatabaseConnector", ref = "v2.4.1")
	install_github("ohdsi/OhdsiSharing", ref = "v0.1.3")
	install_github("ohdsi/FeatureExtraction", ref = "v2.2.5")
	install_github("ohdsi/CohortMethod", ref = "v3.1.0")
	install_github("ohdsi/EmpiricalCalibration", ref = "v2.0.0")
	install_github("ohdsi/MethodEvaluation", ref = "v1.1.0")
```


	If you experience problems on Windows where rJava can't find Java, one solution may be to add `args = "--no-multiarch"` to each `install_github` call, for example:
```{r}
install_github("ohdsi/SqlRender", args = "--no-multiarch")
```
	
	Alternatively, ensure that you have installed only the 64-bit versions of R and Java, as described in [the Book of OHDSI](https://ohdsi.github.io/TheBookOfOhdsi/OhdsiAnalyticsTools.html#installR)
	
2. In `R`, use the following `devtools` command to install the TdexaCpds package:
```{r}
install() # Note: it is ok to delete inst/doc
```


3. Once installed, you can execute the study by modifying and using the code below. For your convenience, this code is also provided under `extras/CodeToRun.R`:

```{r}
library(TdexaCpds)
	
	# Optional: specify where the temporary files (used by the ff package) will be created:
	options(fftempdir = "c:/FFtemp")
	
	# Maximum number of cores to be used:
	maxCores <- parallel::detectCores()
	
	# Minimum cell count when exporting data:
	minCellCount <- 5
	
	# The folder where the study intermediate and result files will be written:
	outputFolder <- "c:/TdexaCpds"
	
	# Details for connecting to the server:
	# See ?DatabaseConnector::createConnectionDetails for help
	connectionDetails <- DatabaseConnector::createConnectionDetails(dbms = "postgresql",
									server = "<your server IP etc>",
									user = "<userID>",
									password = "<password>")
	
	# The name of the database schema where the CDM data can be found:
	cdmDatabaseSchema <- "cdm_synpuf"
	
	# The name of the database schema and table where the study-specific cohorts will be instantiated:
	cohortDatabaseSchema <- "scratch.dbo"
	cohortTable <- "my_study_cohorts"
	
	# Some meta-information that will be used by the export function:
	databaseId <- "<your database ID>"
	databaseName <- "<your database name>"
	databaseDescription <- "<describe your database characteristics and contents>"
	
	# For Oracle: define a schema that can be used to emulate temp tables:
	oracleTempSchema <- NULL
	
	execute(connectionDetails = connectionDetails,
            cdmDatabaseSchema = cdmDatabaseSchema,
            cohortDatabaseSchema = cohortDatabaseSchema,
            cohortTable = cohortTable,
            oracleTempSchema = oracleTempSchema,
            outputFolder = outputFolder,
            databaseId = databaseId,
            databaseName = databaseName,
            databaseDescription = databaseDescription,
            createCohorts = TRUE,
            synthesizePositiveControls = TRUE,
            runAnalyses = TRUE,
            runDiagnostics = TRUE,
            packageResults = TRUE,
            maxCores = maxCores)
```


4. Upload the file ```export/Results<DatabaseId>.zip``` in the output folder to the study coordinator:

```{r}
submitResults("export/Results<DatabaseId>.zip", key = "<key>", secret = "<secret>")
```


	Where ```key``` and ```secret``` are the credentials provided to you personally by the study coordinator.
		
5. To view the results, use the Shiny app:

```{r}
prepareForEvidenceExplorer("Result<databaseId>.zip", "/shinyData")
	launchEvidenceExplorer("/shinyData", blind = TRUE)
```


  Note that you can save plots from within the Shiny app. It is possible to view results from more than one database by applying `prepareForEvidenceExplorer` to the Results file from each database, and using the same data folder. Set `blind = FALSE` if you wish to be unblinded to the final results.



# Preparation for the experiments

We need to tell R how to connect to the server where the data are. `CohortMethod` uses the `DatabaseConnector` package, which provides the `createConnectionDetails` function. Type `?createConnectionDetails` for the specific settings required for the various database management systems (DBMS). For example, one might connect to a PostgreSQL database using this code:

```{r eval=TRUE}
connectionDetails <- DatabaseConnector::createConnectionDetails(dbms = "postgresql",
									server = "<your server IP etc>",
									user = "<userID>",
									password = "<password>")
	
	# The name of the database schema where the CDM data can be found:
	cdmDatabaseSchema <- "cdm_synpuf"
	
	# The name of the database schema and table where the study-specific cohorts will be instantiated:
	cohortDatabaseSchema <- "scratch.dbo"
	cohortTable <- "my_study_cohorts"
	outputFolder <- "c:/TdexaCpds"
	
<<<<<<< HEAD
=======
```

The last three lines define the `cdmDatabaseSchema`, `cohortDatabaseSchema`, and `outputFolder` variables. We'll use these later to tell R where the data in CDM format live,  where we want to write intermediate tables, and where the intermediate and output files should be stored in the local file system. Note that for Microsoft SQL Server, databaseschemas need to specify both the database and the schema, so for example `cdmDatabaseSchema <- "my_cdm_data.dbo"`.

```{r}
setCutoffPercentile <- function(x) {
  upperPercentileGroupCohortDefID <<- 100 - x
  lowerPercentileGroupCohortDefID <<- x
  cutoffPercentile <<- x
}
setCutoffPercentile(90)
PerDay <- "'false'"
>>>>>>> 26ec58212c7bb7a8bd0c5abd703db41ea6be0a93
```

The last three lines define the `cdmDatabaseSchema`, `cohortDatabaseSchema`, and `outputFolder` variables. We'll use these later to tell R where the data in CDM format live,  where we want to write intermediate tables, and where the intermediate and output files should be stored in the local file system. Note that for Microsoft SQL Server, databaseschemas need to specify both the database and the schema, so for example `cdmDatabaseSchema <- "my_cdm_data.dbo"`.

We also need to prepare our exposures and outcomes of interest. The drug_era table in the OMOP Common Data Model already contains prespecified cohorts of users at the ingredient level, so we will use that for the exposures. For the outcomes, we want to restrict our analysis only to those outcomes that are recorded in an inpatient setting, so we will need to create a custom cohort table. For this example, we want to include osteoporosis (concept ID 192671) as well as a set of 35 negative controls. Negative controls are defined as those outcomes where there is no evidence that either the target drug (celexocib) or comparator drug (diclofenac) causes the outcome. 

We create a text file called *SystemicSteroidCohortOutcome.sql* with the following content:

```sql
/***********************************
File SystemicSteroidCohortOutcome.sql
***********************************/
IF OBJECT_ID('@resultsDatabaseSchema.outcomes', 'U') IS NOT NULL
  DROP TABLE @resultsDatabaseSchema.outcomes;

SELECT ancestor_concept_id AS cohort_definition_id,
	condition_start_date AS cohort_start_date,
	condition_end_date AS cohort_end_date,
	condition_occurrence.person_id AS subject_id
INTO @resultsDatabaseSchema.outcomes
FROM @cdmDatabaseSchema.condition_occurrence
INNER JOIN @cdmDatabaseSchema.visit_occurrence
	ON condition_occurrence.visit_occurrence_id = visit_occurrence.visit_occurrence_id
INNER JOIN @cdmDatabaseSchema.concept_ancestor
	ON condition_concept_id = descendant_concept_id
WHERE ancestor_concept_id IN (80502, 4344387, 75053, 73754, 80004, 139099,
141932, 192367, 193739, 197236, 313459, 319843, 321596, 375292, 380094, 433753, 433811, 436665, 436676, 438134, 440358, 440374, 443617, 443800, 4288310 )
	AND visit_occurrence.visit_concept_id IN (9201, 9203);
```
This is parameterized SQL which can be used by the `SqlRender` package. We use parameterized SQL so we do not have to pre-specify the names of the CDM and result schemas. That way, if we want to run the SQL on a different schema, we only need to change the parameter values; we do not have to change the SQL code. By also making use of translation functionality in `SqlRender`, we can make sure the SQL code can be run in many different environments.

```{r eval=FALSE}
library(SqlRender)
setwd("C:/Users/estone/Documents/project/SteroidCohortMethod")
sql <- readSql("inst/sql/sql_server/SystemicSteroidGroupByPercentage.sql")
sql <- render(sql,
              cdmDatabaseSchema = cdmDatabaseSchema, 
              resultsDatabaseSchema = resultsDatabaseSchema,
              upperPercentileGroupCohortDefID = upperPercentileGroupCohortDefID,
              lowerPercentileGroupCohortDefID = lowerPercentileGroupCohortDefID,
              cutoffPercentile = cutoffPercentile,
              PerDay = PerDay)
sql <- translate(sql, targetDialect = connectionDetails$dbms)
executeSql(connection, sql)

# Find cutoff value

  sql <- paste("SELECT AVG(result) AS cutoffValue
                FROM (
                  SELECT min(conversion) AS result FROM #targetGroup WHERE percentage >= @cutoffPercentile
                  UNION ALL
                  SELECT max(conversion) AS result FROM #targetGroup WHERE percentage < @cutoffPercentile
                ) AS alias")
  sql <- render(sql, cutoffPercentile = cutoffPercentile)
  sql <- translate(sql, targetDialect = connectionDetails$dbms)
  cutoffValue <- querySql(connection, sql)

```

In this code, we first read the SQL from the file into memory. In the next line, we replace the two parameter names with the actual values. We then translate the SQL into the dialect appropriate for the DBMS we already specified in the `connectionDetails`. Next, we connect to the server, and submit the rendered and translated SQL.

# Specifying hypotheses of interest

The first group of arguments define the target, comparator, and outcome. Here we demonstrate how to create one set, and add that set to a list:

```{r eval=FALSE}
tcos <- createTargetComparatorOutcomes(targetId = upperPercentileGroupCohortDefID,
                                       comparatorId = lowerPercentileGroupCohortDefID,
                                       outcomeIds = c(80502, 4344387, 75053, 73754, 80004, 139099, 141932, 192367, 193739, 197236, 313459, 319843, 321596, 375292, 380094, 433753, 433811, 436665, 436676, 438134, 440358, 440374, 443617, 443800, 4288310))

targetComparatorOutcomesList <- list(tcos)
```

We defined the target to be celecoxib (concept ID 1118084), the comparator to be diclofenac (concept ID 1124300), and the outcomes of interest are GI-bleed (concept ID 192671) and a large number of negative control outcomes. 

A convenient way to save `targetComparatorOutcomesList` to file is by using the `saveTargetComparatorOutcomesList` function, and we can load it again using the `loadTargetComparatorOutcomesList` function.

# Specifying analyses

The second group of arguments are not specific to a hypothesis of interest, and comprise the majority of arguments. For each function that will be called during the execution of the analyses, a companion function is available that has (almost) the same arguments. For example, for the `trimByPs()` function there is the `createTrimByPsArgs()` function. These companion functions can be used to create the arguments to be used during execution:

```{r eval=TRUE}
corticosteroid <- 21602722

covarSettings <- createDefaultCovariateSettings(excludedCovariateConceptIds = corticosteroid,
                                                addDescendantsToExclude = TRUE)
#covarSettings <- createCovariateSettings(useDemographicsGender = TRUE,
#                                         useDemographicsAgeGroup = TRUE)

getDbCmDataArgs <- createGetDbCohortMethodDataArgs(washoutPeriod = 90,
                                                   restrictToCommonPeriod = FALSE,
                                                   firstExposureOnly = TRUE,
                                                   removeDuplicateSubjects = "remove all",
                                                   studyStartDate = "",
                                                   studyEndDate = "",
                                                   excludeDrugsFromCovariates = FALSE,
                                                   covariateSettings = covarSettings)

createStudyPopArgs <- createCreateStudyPopulationArgs(firstExposureOnly = TRUE,
                                                      restrictToCommonPeriod = FALSE,
                                                      washoutPeriod = 0,
                                                      removeDuplicateSubjects = FALSE,
                                                      removeSubjectsWithPriorOutcome = TRUE,
                                                      priorOutcomeLookback = 99999,
                                                      minDaysAtRisk = 1,
                                                      riskWindowStart = 1,
                                                      addExposureDaysToStart = NULL,
                                                      startAnchor = "cohort start",
                                                      riskWindowEnd = 99999,
                                                      addExposureDaysToEnd = NULL,
                                                      endAnchor = "cohort end",
                                                      censorAtNewRiskWindow = FALSE)

fitOutcomeModelArgs1 <- createFitOutcomeModelArgs(modelType = "cox")
```

Any argument that is not explicitly specified by the user will assume the default value specified in the function. We can now combine the arguments for the various functions into a single analysis:

```{r eval=TRUE}
cmAnalysis1 <- createCmAnalysis(analysisId = 1,
                                description = "No matching, simple outcome model",
                                getDbCohortMethodDataArgs = getDbCmDataArgs,
                                createStudyPopArgs = createStudyPopArgs,
                                fitOutcomeModel = TRUE,
                                fitOutcomeModelArgs = fitOutcomeModelArgs1)
```

Note that we have assigned an analysis ID (1) to this set of arguments. We can use this later to link the results back to this specific set of choices. We also include a short description of the analysis.

We can easily create more analyses, for example by using matching, stratification, inverse probability of treatment weighting, or by using more sophisticated outcome models:

```{r eval=TRUE}
createPsArgs <- createCreatePsArgs() # Use default settings only

matchOnPsArgs <- createMatchOnPsArgs(maxRatio = 100)

fitOutcomeModelArgs2 <- createFitOutcomeModelArgs(modelType = "cox",
                                                  stratified = TRUE)

cmAnalysis2 <- createCmAnalysis(analysisId = 2,
                                description = "Matching",
                                getDbCohortMethodDataArgs = getDbCmDataArgs,
                                createStudyPopArgs = createStudyPopArgs,
                                createPs = TRUE,
                                createPsArgs = createPsArgs,
                                matchOnPs = TRUE,
                                matchOnPsArgs = matchOnPsArgs,
                                fitOutcomeModel = TRUE,
                                fitOutcomeModelArgs = fitOutcomeModelArgs1)

stratifyByPsArgs <- createStratifyByPsArgs(numberOfStrata = 5)

cmAnalysis3 <- createCmAnalysis(analysisId = 3,
                                description = "Stratification",
                                getDbCohortMethodDataArgs = getDbCmDataArgs,
                                createStudyPopArgs = createStudyPopArgs,
                                createPs = TRUE,
                                createPsArgs = createPsArgs,
                                stratifyByPs = TRUE,
                                stratifyByPsArgs = stratifyByPsArgs,
                                fitOutcomeModel = TRUE,
                                fitOutcomeModelArgs = fitOutcomeModelArgs2)

fitOutcomeModelArgs3 <- createFitOutcomeModelArgs(modelType = "cox",
                                                  inversePtWeighting = TRUE)

cmAnalysis4 <- createCmAnalysis(analysisId = 4,
                                description = "Inverse probability weighting",
                                getDbCohortMethodDataArgs = getDbCmDataArgs,
                                createStudyPopArgs = createStudyPopArgs,
                                createPs = TRUE,
                                createPsArgs = createPsArgs,
                                fitOutcomeModel = TRUE,
                                fitOutcomeModelArgs = fitOutcomeModelArgs3)

fitOutcomeModelArgs4 <- createFitOutcomeModelArgs(useCovariates = TRUE,
                                                  modelType = "cox",
                                                  stratified = TRUE)

cmAnalysis5 <- createCmAnalysis(analysisId = 5,
                                description = "Matching plus full outcome model",
                                getDbCohortMethodDataArgs = getDbCmDataArgs,
                                createStudyPopArgs = createStudyPopArgs,
                                createPs = TRUE,
                                createPsArgs = createPsArgs,
                                matchOnPs = TRUE,
                                matchOnPsArgs = matchOnPsArgs,
                                fitOutcomeModel = TRUE,
                                fitOutcomeModelArgs = fitOutcomeModelArgs4)

# interactionCovariateIds <- c(8532001, 201826210, 21600960413) # Female, T2DM, concurent use of antithrombotic agents
# 
# fitOutcomeModelArgs5 <- createFitOutcomeModelArgs(modelType = "cox",
#                                                   stratified = TRUE,
#                                                   interactionCovariateIds = interactionCovariateIds)
# 
# cmAnalysis6 <- createCmAnalysis(analysisId = 6,
#                                 description = "Stratification plus interaction terms",
#                                 getDbCohortMethodDataArgs = getDbCmDataArgs,
#                                 createStudyPopArgs = createStudyPopArgs,
#                                 createPs = TRUE,
#                                 createPsArgs = createPsArgs,
#                                 stratifyByPs = TRUE,
#                                 stratifyByPsArgs = stratifyByPsArgs,
#                                 fitOutcomeModel = TRUE,
#                                 fitOutcomeModelArgs = fitOutcomeModelArgs5)
```

These analyses can be combined in a list:

```{r eval=TRUE}
cmAnalysisList <- list(cmAnalysis1, 
                       cmAnalysis2, 
                       cmAnalysis3, 
                       cmAnalysis4, 
                       cmAnalysis5)
#,                       cmAnalysis6)
```

A convenient way to save `cmAnalysisList` to file is by using the `saveCmAnalysisList` function, and we can load it again using the `loadCmAnalysisList` function.

## Target and comparator selection strategies

Often a new-user cohort design is used for comparative effectiveness studies, where the selection of the comparator is part of the hypothesis of interest: 'Does use of drug A lead to an increased risk compared to use of drug B?', where B is the comparator. But sometimes, the design is used for safety assessment: 'Does use of drug A lead to an increased risk?' In this case the comparator is a proxy for the counterfactual of no treatment. For example, we could pick the comparator to be a drug known not to cause the outcome. we can argue that the selection of the comparator then becomes part of the analyses specification, not the hypothesis of interest, and we can have different strategies for selecting a comparator: Do we for instance pick a drug in the same class, or a drug with the same indication?

In the situation where the comparator choice becomes part of the analyses, we can specify multiple comparators per hypothesis of interest by using a list:

```{r eval=TRUE}
# comparatorIds = list(drugInSameClass = 1124300,
#                      drugWithSameIndication = 1125315)
# 
# tcos <- createTargetComparatorOutcomes(targetId = 1118084,
#                                      comparatorId = comparatorIds,
#                                      outcomeIds = 192671)
# 
# targetComparatorOutcomesList2 <- list(tcos)
```

When we specify an analysis, we can then refer to one comparator or another:

```{r eval=TRUE}
# cmAnalysis1 <- createCmAnalysis(analysisId = 1,
#                                 description = "Analysis using drug in same class",
#                                 comparatorType = "drugInSameClass",
#                                 getDbCohortMethodDataArgs = getDbCmDataArgs,
#                                 createStudyPopArgs = createStudyPopArgs,
#                                 createPs = TRUE,
#                                 createPsArgs = createPsArgs,
#                                 matchOnPs = TRUE,
#                                 matchOnPsArgs = matchOnPsArgs,
#                                 fitOutcomeModel = TRUE,
#                                 fitOutcomeModelArgs = fitOutcomeModelArgs1)
# 
# cmAnalysis2 <- createCmAnalysis(analysisId = 2,
#                                 description = "Analysis using drug with same indication",
#                                 comparatorType = "drugWithSameIndication",
#                                 getDbCohortMethodDataArgs = getDbCmDataArgs,
#                                 createStudyPopArgs = createStudyPopArgs,
#                                 createPs = TRUE,
#                                 createPsArgs = createPsArgs,
#                                 matchOnPs = TRUE,
#                                 matchOnPsArgs = matchOnPsArgs,
#                                 fitOutcomeModel = TRUE,
#                                 fitOutcomeModelArgs = fitOutcomeModelArgs1)
# 
# cmAnalysisList2 <- list(cmAnalysis1, cmAnalysis2)
```

In this example, the first analysis (analysisID = 1) will use concept 1124300 as comparator, whilst the second analysis analysis (analysisID = 2) will use concept 1125315 as comparator.

The same mechanism can be used to specify types for the targetId.

# Executing multiple analyses

We can now run the analyses against the hypotheses of interest using the `runCmAnalyses()` function. This function will run all specified analyses against all hypotheses of interest, meaning that the total number of outcome models is `length(cmAnalysisList) * length(targetComparatorOutcomesList)` (if all analyses specify an outcome model should be fitted).

```{r eval=FALSE}
result <- runCmAnalyses(connectionDetails = connectionDetails,
                        cdmDatabaseSchema = cdmDatabaseSchema,
                        exposureDatabaseSchema = resultsDatabaseSchema,
                        exposureTable = "SystemicSteroid",
                        outcomeDatabaseSchema = resultsDatabaseSchema,
                        outcomeTable = "SystemicSteroid",
                        cdmVersion = 5,
                        outputFolder = outputFolder,
                        cmAnalysisList = cmAnalysisList,
                        targetComparatorOutcomesList = targetComparatorOutcomesList,
                        getDbCohortMethodDataThreads = 1,
                        createPsThreads = 1,
                        psCvThreads = 10,
                        createStudyPopThreads = 4,
                        trimMatchStratifyThreads = 10,
                        fitOutcomeModelThreads = 4,
                        outcomeCvThreads = 10)
```

In the code above, we provide the arguments for connecting to the database, which schemas and tables to use, as well as the analyses and hypotheses of interest. The `outputFolder` specifies where the outcome models and intermediate files will be written. We also instruct `CohortMethod` to use multiple threads for various stages in the analyses, meaning these will be executed in parallel on multiple CPUs in the computer. Multithreading can significantly reduce execution time, but will require more system resources such as memory and temporary disk space. 

## Restarting

If for some reason the execution was interrupted, you can restart by re-issuing the `runCmAnalyses()` command. Any intermediate and final products that have already been completed and written to disk will be skipped.

# Retrieving the results

The result of the `runCmAnalyses()` is a data frame with one row per target-target-outcome-analysis combination. It provides the file names of the intermediate and end-result files that were constructed. For example, we can retrieve and plot the propensity scores for the combination of our target, comparator, outcome of interest, and last analysis:

```{r eval=FALSE}
psFile <- result$psFile[result$targetId == upperPercentileGroupCohortDefID & 
                        result$comparatorId == lowerPercentileGroupCohortDefID & 
                        result$outcomeId == 4344387 &
                        result$analysisId == 2]
ps <- readRDS(file.path(outputFolder, psFile))
plotPs(ps)
```
```{r echo=FALSE,message=FALSE}
if (file.exists("e:/temp/cohortMethodVignette2/outcomeModelReference.rds")) {
  outputFolder <- "e:/temp/cohortMethodVignette2"
  result <- readRDS("e:/temp/cohortMethodVignette2/outcomeModelReference.rds")
  psFile <- result$psFile[result$targetId == 1 & 
                            result$comparatorId == 2 & 
                            result$outcomeId == 80502 &
                            result$analysisId == 5]
  ps <- readRDS(file.path(outputFolder, psFile))
  plotPs(ps)
}
```

Note that some of the file names will appear several times in the table. For example, analysis 3 and 5 only differ in terms of the outcome model, and will share the same propensity score and stratification files.

We can create a summary of the results using `summarizeAnalyses()`:
```{r eval=FALSE}
analysisSum <- summarizeAnalyses(result, outputFolder)
head(analysisSum)
```
```{r echo=FALSE,message=FALSE}
if (file.exists("e:/temp/cohortMethodVignette2/analysisSummary.rds")) {
  analysisSum <- readRDS("e:/temp/cohortMethodVignette2/analysisSummary.rds")
  head(analysisSum)
}
```

This tells us, per target-comparator-outcome-analysis combination, the estimated relative risk and 95% confidence interval, as well as the number of people in the treated and comparator group (after trimming and matching if applicable), and the number of outcomes observed for those groups within the specified risk windows.

## Empirical calibration

Now that we have produced estimates for all outcomes including our negative controls, we can perform empirical calibration to estimate the bias of the various analyses included in our study. We will create the calibration effect plots for every analysis ID. In each plot, the blue dots represent our negative control outcomes, and the yellow diamond represents our health outcome of interest: GI bleed. An unbiased, well-calibrated analysis should have 95% of the negative controls between the dashed lines (ie. 95% should have p > .05).

```{r eval=FALSE}
install.packages("EmpiricalCalibration")
library(EmpiricalCalibration)

# Analysis 1: No matching, simple outcome model
negCons <- analysisSum[analysisSum$analysisId == 1 & analysisSum$outcomeId != 80502, ]
hoi <-  analysisSum[analysisSum$analysisId == 1 & analysisSum$outcomeId == 80502, ]
null <- fitNull(negCons$logRr, negCons$seLogRr)
plotCalibrationEffect(negCons$logRr, negCons$seLogRr, hoi$logRr, hoi$seLogRr, null)
```
```{r echo=FALSE,message=FALSE,warning=FALSE,eval=TRUE}
if (file.exists("e:/temp/cohortMethodVignette2/analysisSummary.rds")) {
  library(EmpiricalCalibration)
  negCons <- analysisSum[analysisSum$analysisId == 1 & analysisSum$outcomeId != 80502, ]
  hoi <-  analysisSum[analysisSum$analysisId == 1 & analysisSum$outcomeId == 80502, ]
  null <- fitNull(negCons$logRr, negCons$seLogRr)
  plotCalibrationEffect(negCons$logRr, negCons$seLogRr, hoi$logRr, hoi$seLogRr, null)
}
```

```{r eval=FALSE}
# Analysis 2: Matching
negCons <- analysisSum[analysisSum$analysisId == 2 & analysisSum$outcomeId != 80502, ]
hoi <-  analysisSum[analysisSum$analysisId == 2 & analysisSum$outcomeId == 80502, ]
null <- fitNull(negCons$logRr, negCons$seLogRr)
plotCalibrationEffect(negCons$logRr, negCons$seLogRr, hoi$logRr, hoi$seLogRr, null)
```
```{r echo=FALSE,message=FALSE,warning=FALSE,eval=TRUE}
if (file.exists("e:/temp/cohortMethodVignette2/analysisSummary.rds")) {
  negCons <- analysisSum[analysisSum$analysisId == 2 & analysisSum$outcomeId != 80502, ]
  hoi <-  analysisSum[analysisSum$analysisId == 2 & analysisSum$outcomeId == 80502, ]
  null <- fitNull(negCons$logRr, negCons$seLogRr)
  plotCalibrationEffect(negCons$logRr, negCons$seLogRr, hoi$logRr, hoi$seLogRr, null)
}
```

```{r eval=FALSE}
# Analysis 3: Stratification
negCons <- analysisSum[analysisSum$analysisId == 3 & analysisSum$outcomeId != 80502, ]
hoi <-  analysisSum[analysisSum$analysisId == 3 & analysisSum$outcomeId == 80502, ]
null <- fitNull(negCons$logRr, negCons$seLogRr)
plotCalibrationEffect(negCons$logRr, negCons$seLogRr, hoi$logRr, hoi$seLogRr, null)
```
```{r echo=FALSE,message=FALSE,warning=FALSE,eval=TRUE}
if (file.exists("e:/temp/cohortMethodVignette2/analysisSummary.rds")) {
  negCons <- analysisSum[analysisSum$analysisId == 3 & analysisSum$outcomeId != 80502, ]
  hoi <-  analysisSum[analysisSum$analysisId == 3 & analysisSum$outcomeId == 80502, ]
  null <- fitNull(negCons$logRr, negCons$seLogRr)
  plotCalibrationEffect(negCons$logRr, negCons$seLogRr, hoi$logRr, hoi$seLogRr, null)
}
```

```{r eval=FALSE}
# Analysis 4: Inverse probability of treatment weighting
negCons <- analysisSum[analysisSum$analysisId == 4 & analysisSum$outcomeId != 80502, ]
hoi <-  analysisSum[analysisSum$analysisId == 4 & analysisSum$outcomeId == 80502, ]
null <- fitNull(negCons$logRr, negCons$seLogRr)
plotCalibrationEffect(negCons$logRr, negCons$seLogRr, hoi$logRr, hoi$seLogRr, null)
```
```{r echo=FALSE,message=FALSE,warning=FALSE,eval=TRUE}
if (file.exists("e:/temp/cohortMethodVignette2/analysisSummary.rds")) {
  negCons <- analysisSum[analysisSum$analysisId == 4 & analysisSum$outcomeId != 80502, ]
  hoi <-  analysisSum[analysisSum$analysisId == 4 & analysisSum$outcomeId == 80502, ]
  null <- fitNull(negCons$logRr, negCons$seLogRr)
  plotCalibrationEffect(negCons$logRr, negCons$seLogRr, hoi$logRr, hoi$seLogRr, null)
}
```

```{r eval=FALSE}
# Analysis 5: Stratification plus full outcome model
negCons <- analysisSum[analysisSum$analysisId == 5 & analysisSum$outcomeId != 80502, ]
hoi <-  analysisSum[analysisSum$analysisId == 5 & analysisSum$outcomeId == 80502, ]
null <- fitNull(negCons$logRr, negCons$seLogRr)
plotCalibrationEffect(negCons$logRr, negCons$seLogRr, hoi$logRr, hoi$seLogRr, null)
```
```{r echo=FALSE,message=FALSE,warning=FALSE,eval=TRUE}
if (file.exists("e:/temp/cohortMethodVignette2/analysisSummary.rds")) {
  negCons <- analysisSum[analysisSum$analysisId == 5 & analysisSum$outcomeId != 80502, ]
  hoi <-  analysisSum[analysisSum$analysisId == 5 & analysisSum$outcomeId == 80502, ]
  null <- fitNull(negCons$logRr, negCons$seLogRr)
  plotCalibrationEffect(negCons$logRr, negCons$seLogRr, hoi$logRr, hoi$seLogRr, null)
}
```

Analysis 6 explored interactions with certain variables. The estimates for these interaction terms are also stored in the analysis summary. We can examine whether these estimates are also consistent with the null. In this example we consider the interaction with 'gender = female' (covariate ID 8532001): 


```{r eval=FALSE}
# Analysis 6: Stratification plus interaction terms
negCons <- analysisSum[analysisSum$analysisId == 6 & analysisSum$outcomeId != 80502, ]
hoi <-  analysisSum[analysisSum$analysisId == 6 & analysisSum$outcomeId == 80502, ]
null <- fitNull(negCons$logRrI8532001, negCons$seLogRrI8532001)
plotCalibrationEffect(logRrNegatives = negCons$logRrI8532001, 
                      seLogRrNegatives = negCons$seLogRrI8532001, 
                      logRrPositives = hoi$logRrI8532001, 
                      seLogRrPositives = hoi$seLogRrI8532001, null)
```
```{r echo=FALSE,message=FALSE,eval=TRUE}
if (file.exists("e:/temp/cohortMethodVignette2/analysisSummary.rds")) {
  negCons <- analysisSum[analysisSum$analysisId == 6 & analysisSum$outcomeId != 80502, ]
  hoi <-  analysisSum[analysisSum$analysisId == 6 & analysisSum$outcomeId == 80502, ]
  null <- fitNull(negCons$logRrI8532001, negCons$seLogRrI8532001)
  plotCalibrationEffect(logRrNegatives = negCons$logRrI8532001, 
                        seLogRrNegatives = negCons$seLogRrI8532001, 
                        logRrPositives = hoi$logRrI8532001, 
                        seLogRrPositives = hoi$seLogRrI8532001, null)
}
```

# Acknowledgments

Considerable work has been dedicated to provide the `CohortMethod` package.

```{r eval=TRUE}
citation("CohortMethod")
```

Further, `CohortMethod` makes extensive use of the `Cyclops` package.

```{r eval=TRUE}
citation("Cyclops")
```

This work is supported in part through the National Science Foundation grant IIS 1251151.
